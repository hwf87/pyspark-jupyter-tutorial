{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a40b577-91f0-488c-aad8-6573df56e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa9ac0-8463-4b90-a433-978bed043728",
   "metadata": {},
   "source": [
    "# Initializing Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9c3fcd-8b39-4de7-a7b9-a830a1bdd6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkContext: <SparkContext master=local appName=Python Spark Example>\n",
      "SparkSession: <pyspark.sql.session.SparkSession object at 0xffff65649210>\n"
     ]
    }
   ],
   "source": [
    "# sc & ss\n",
    "AppName, Mode = \"Python Spark Example\", \"local\"\n",
    "conf = SparkConf().setAppName(AppName).setMaster(Mode)\n",
    "sc = SparkContext(conf=conf)\n",
    "ss = SparkSession.builder.getOrCreate()\n",
    "print(f\"SparkContext: {sc}\")\n",
    "print(f\"SparkSession: {ss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2688955-a584-40db-b471-f7138613327b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab7f4d-b030-4134-afa7-a3a3e7c1eb1b",
   "metadata": {},
   "source": [
    "## Create RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a94f03e3-8f01-4fb0-865b-d9d081f27de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'pyspark.rdd.RDD'>, Data: [[1, 2, 3], [4, 5], [6], [7, 8, 9, 10]]\n"
     ]
    }
   ],
   "source": [
    "# with Parallelized Collections\n",
    "data = [\n",
    "    [1, 2, 3], \n",
    "    [4, 5],\n",
    "    [6],\n",
    "    [7, 8, 9, 10]\n",
    "]\n",
    "persist_data = sc.parallelize(data).persist()\n",
    "print(f\"Type: {type(persist_data)}, Data: {persist_data.collect()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ffe14-7308-4def-a5d0-c53e5299e7e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RDD Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e42edc-26d2-4c8a-ae2f-6dcce7d72672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " first: [1, 2, 3]\n",
      " take: [[1, 2, 3], [4, 5]]\n",
      " count: 4\n",
      " collect: [[1, 2, 3], [4, 5], [6], [7, 8, 9, 10]]\n",
      " countByKey: defaultdict(<class 'int'>, {1: 1, 4: 1, 6: 1, 7: 1})\n"
     ]
    }
   ],
   "source": [
    "# Basic Operation \n",
    "print(f\" first: {persist_data.first()}\")\n",
    "print(f\" take: {persist_data.take(2)}\")\n",
    "print(f\" count: {persist_data.count()}\")\n",
    "print(f\" collect: {persist_data.collect()}\")\n",
    "print(f\" countByKey: {persist_data.countByKey()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7d4a38-8bff-4edf-99f1-f80242763928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Result: [[2, 3, 4], [5, 6], [7], [8, 9, 10, 11]]\n"
     ]
    }
   ],
   "source": [
    "# Map\n",
    "result = persist_data.map(lambda x: [i+1 for i in x])\n",
    "print(f\" Result: {result.collect()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5032d9d-9712-4e57-8273-188a031b9313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Result: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "# flatMap\n",
    "result = persist_data.flatMap(lambda x: [i+1 for i in x])\n",
    "print(f\" Result: {result.collect()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789f3149-a260-41a7-8380-c1805a3bd115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Result: [[7, 8, 9, 10]]\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "result = persist_data.filter(lambda x: 7 in x)\n",
    "print(f\" Result: {result.collect()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ac86eda-cf12-46b1-9b68-2782dbf01abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Result_1: 10\n",
      " Result_2: 28\n"
     ]
    }
   ],
   "source": [
    "# foreach: Run a function func on each element of the dataset. \n",
    "# This is usually done for side effects such as updating an Accumulator or interacting with external storage systems. \n",
    "accum = sc.accumulator(0)\n",
    "\n",
    "class MyAccumulator:\n",
    "    def AccumulateByLength(nums: List[int]) -> None:\n",
    "        target = len(nums)\n",
    "        accum.add(target)\n",
    "    def AccumulateByFirstNum(nums: List[int]) -> None:\n",
    "        target = nums[0]\n",
    "        accum.add(target)\n",
    "\n",
    "persist_data.foreach(MyAccumulator.AccumulateByLength)  # 3+2+1+4 = 10\n",
    "print(f\" Result_1: {accum.value}\") #Accessed by driver\n",
    "\n",
    "persist_data.foreach(MyAccumulator.AccumulateByFirstNum) # 10+ (1+4+6+7) = 28\n",
    "print(f\" Result_2: {accum.value}\") #Accessed by driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6273243-2002-47aa-9e83-d4a17f134b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Result_1: [[2, 3, 4], [5, 6], [7], [8, 9, 10, 11]]\n",
      " Result_2: [[0, 1, 2], [3, 4], [5], [6, 7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "# map: Return a new distributed dataset formed by passing each element of the source through a function func.\n",
    "# Passing Functions to Spark\n",
    "\n",
    "class MyComputer:\n",
    "    def plusone(nums: List[int]) -> list:\n",
    "        return [i+1 for i in nums]\n",
    "    def minusone(nums: List[int]) -> list:\n",
    "        return [i-1 for i in nums]\n",
    "\n",
    "result_1 = persist_data.map(MyComputer.plusone)\n",
    "result_2 = persist_data.map(MyComputer.minusone)\n",
    "print(f\" Result_1: {result_1.collect()}\")\n",
    "print(f\" Result_2: {result_2.collect()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa86f57-6ea6-4b0b-bd33-92f5a98a2650",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Spark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab78b8a-05ec-4018-8179-f35ee8605923",
   "metadata": {},
   "source": [
    "## Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "afa9eb97-09ea-4a89-bd64-b4130a9d69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare json data\n",
    "people_json = [\n",
    "    {\"Name\": \"Jacky\", \"Age\": 27, \"Gender\": \"Male\", \"Country\": \"Taiwan\"},\n",
    "    {\"Name\": \"John\", \"Age\": 32, \"Gender\": \"Male\", \"Country\": \"Taiwan\"},\n",
    "    {\"Name\": \"Tom\", \"Age\": 42, \"Gender\": \"Male\", \"Country\": \"Japan\"},\n",
    "    {\"Name\": \"Mark\", \"Age\": 16, \"Gender\": \"Male\", \"Country\": \"Taiwan\"},\n",
    "    {\"Name\": \"Sandy\", \"Age\": 23, \"Gender\": \"Female\", \"Country\": \"US\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "37ce6ee4-6fa0-442b-8c24-b61e69d8af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: long (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      "\n",
      "+---+-------+------+-----+\n",
      "|Age|Country|Gender| Name|\n",
      "+---+-------+------+-----+\n",
      "| 27| Taiwan|  Male|Jacky|\n",
      "| 32| Taiwan|  Male| John|\n",
      "| 42|  Japan|  Male|  Tom|\n",
      "| 16| Taiwan|  Male| Mark|\n",
      "| 23|     US|Female|Sandy|\n",
      "+---+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use rdd.toDF() to create a spark DataFrame\n",
    "people_json = sc.parallelize(people_json)\n",
    "sample_df = persist_people_json.toDF()\n",
    "sample_df.printSchema()\n",
    "sample_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "409dee16-33bd-4f74-b6c8-48b54226aba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = false)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+-----+---+------+-------+\n",
      "|Name |Age|Gender|Country|\n",
      "+-----+---+------+-------+\n",
      "|Jacky|27 |Male  |Taiwan |\n",
      "|John |32 |Male  |Taiwan |\n",
      "|Tom  |42 |Male  |Japan  |\n",
      "|Mark |16 |Male  |Taiwan |\n",
      "|Sandy|23 |Female|US     |\n",
      "+-----+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with a specified schema\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "deptSchema = StructType([       \n",
    "    StructField('Name', StringType(), False),\n",
    "    StructField('Age', IntegerType(), True),\n",
    "    StructField('Gender', StringType(), True),\n",
    "    StructField('Country', StringType(), True)\n",
    "])\n",
    "\n",
    "df = ss.createDataFrame(people_json, schema = deptSchema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e1cdc4-e2f4-4f07-9cbc-4d6491d759f4",
   "metadata": {},
   "source": [
    "## DataFrame Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2148ed5d-1357-4160-ad58-8ec0355dbf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+\n",
      "| Name|Age|Country|\n",
      "+-----+---+-------+\n",
      "|Jacky| 27| Taiwan|\n",
      "| John| 32| Taiwan|\n",
      "+-----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select people from Taiwan and older than 25\n",
    "df.filter((df['Country'] == \"Taiwan\") & (df['Age'] > 25)) \\\n",
    "    .select(df['Name'], df['Age'], df['Country']) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1a91fa74-e1ac-4cfd-8a5a-cce5e2da536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-------+-------+-------+-----------+\n",
      "|Country|Count_Country|Min_Age|Max_Age|Sum_Age|Average_Age|\n",
      "+-------+-------------+-------+-------+-------+-----------+\n",
      "| Taiwan|            3|     16|     32|     75|       25.0|\n",
      "|     US|            1|     23|     23|     23|       23.0|\n",
      "|  Japan|            1|     42|     42|     42|       42.0|\n",
      "+-------+-------------+-------+-------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy & where with functions\n",
    "from pyspark.sql.functions import col, sum, avg, max, min\n",
    "df.groupBy(\"Country\") \\\n",
    "  .agg(\n",
    "    count(\"Country\").alias(\"Count_Country\"),\n",
    "    min(\"Age\").alias(\"Min_Age\"),\n",
    "    max(\"Age\").alias(\"Max_Age\"),\n",
    "    sum(\"Age\").alias(\"Sum_Age\"),\n",
    "    avg(\"Age\").alias(\"Average_Age\")\n",
    "  ) \\\n",
    "  .where(col(\"Average_Age\") >= 10) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ea90123a-4ecf-49df-ac5d-9276642424bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+-------+---------+---------+\n",
      "| Name|Age|Gender|Country| New Name|Power Age|\n",
      "+-----+---+------+-------+---------+---------+\n",
      "|Jacky| 27|  Male| Taiwan|NEW_Jacky|      729|\n",
      "| John| 32|  Male| Taiwan| NEW_John|     1024|\n",
      "|  Tom| 42|  Male|  Japan|  NEW_Tom|     1764|\n",
      "| Mark| 16|  Male| Taiwan| NEW_Mark|      256|\n",
      "|Sandy| 23|Female|     US|NEW_Sandy|      529|\n",
      "+-----+---+------+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UDF\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "class MyUdf:\n",
    "    def newname(s: str) -> str:\n",
    "        return f\"NEW_{s}\"\n",
    "    def powerage(i: int) -> int:\n",
    "        return i*i\n",
    "\n",
    "# Convert function to udf\n",
    "newname_udf = udf(lambda x: MyUdf.newname(x), StringType())\n",
    "powerage_udf = udf(lambda x: MyUdf.powerage(x), IntegerType())\n",
    "\n",
    "# Apply udf\n",
    "df1 = df.withColumn(\"New Name\", newname_udf(col(\"Name\")))\n",
    "df1 = df1.withColumn(\"Power Age\", powerage_udf(col(\"Age\")))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "320a178d-b1e9-4d17-81a3-92e21375d2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'pyspark.pandas.frame.DataFrame'> \n",
      "     Name  Age Gender Country\n",
      "0  Jacky   27   Male  Taiwan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "      <th>New Name</th>\n",
       "      <th>Power Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacky</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NEW_Jacky</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NEW_John</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>Japan</td>\n",
       "      <td>NEW_Tom</td>\n",
       "      <td>1764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark</td>\n",
       "      <td>16</td>\n",
       "      <td>Male</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NEW_Mark</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sandy</td>\n",
       "      <td>23</td>\n",
       "      <td>Female</td>\n",
       "      <td>US</td>\n",
       "      <td>NEW_Sandy</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age  Gender Country   New Name  Power Age\n",
       "0  Jacky   27    Male  Taiwan  NEW_Jacky        729\n",
       "1   John   32    Male  Taiwan   NEW_John       1024\n",
       "2    Tom   42    Male   Japan    NEW_Tom       1764\n",
       "3   Mark   16    Male  Taiwan   NEW_Mark        256\n",
       "4  Sandy   23  Female      US  NEW_Sandy        529"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PySpark DataFrame doesn’t contain the apply() function \n",
    "# However, we can leverage Pandas DataFrame.apply() by running Pandas API over PySpark.\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "psdf = ps.DataFrame(df)\n",
    "print(f\"Type: {type(psdf)} \\n {psdf.head(1)}\")\n",
    "\n",
    "# Apply function to psdf\n",
    "psdf[\"New Name\"] = psdf[\"Name\"].apply(MyUdf.newname)\n",
    "psdf[\"Power Age\"] = psdf[\"Age\"].apply(MyUdf.powerage)\n",
    "psdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716951f-cb32-490b-b134-e79bbdd573b0",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf2186f-10b2-410f-b298-4d38677a8f23",
   "metadata": {},
   "source": [
    "## Create TempView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "39d6c27e-e2f1-4e35-b9af-64e71e911fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"PEOPLE_TABLE\")\n",
    "df.createOrReplaceGlobalTempView(\"GLOBAL_PEOPLE_TABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4889c5c-f805-43db-ada2-cd0c83cc9835",
   "metadata": {},
   "source": [
    "## SQL Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "80b73bb8-47bb-41fd-bfd5-d1d377137d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+-------+\n",
      "| Name|Age|Gender|Country|\n",
      "+-----+---+------+-------+\n",
      "|Jacky| 27|  Male| Taiwan|\n",
      "| John| 32|  Male| Taiwan|\n",
      "|  Tom| 42|  Male|  Japan|\n",
      "| Mark| 16|  Male| Taiwan|\n",
      "|Sandy| 23|Female|     US|\n",
      "+-----+---+------+-------+\n",
      "\n",
      "+-----+---+------+-------+\n",
      "| Name|Age|Gender|Country|\n",
      "+-----+---+------+-------+\n",
      "|Jacky| 27|  Male| Taiwan|\n",
      "| John| 32|  Male| Taiwan|\n",
      "|  Tom| 42|  Male|  Japan|\n",
      "| Mark| 16|  Male| Taiwan|\n",
      "|Sandy| 23|Female|     US|\n",
      "+-----+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select from table / global table\n",
    "ss.sql(\"SELECT * FROM PEOPLE_TABLE\").show()\n",
    "ss.sql(\"SELECT * FROM global_temp.GLOBAL_PEOPLE_TABLE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7c8e2f47-cb52-4f40-b918-2f11f3f36d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| Name|NEW_Name|\n",
      "+-----+--------+\n",
      "|Jacky|   JACKY|\n",
      "| John|    JOHN|\n",
      "|  Tom|     TOM|\n",
      "| Mark|    MARK|\n",
      "|Sandy|   SANDY|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql operation\n",
    "ss.sql(\"\"\"\n",
    "        SELECT\n",
    "           Name, Upper(Name) AS NEW_Name\n",
    "        FROM\n",
    "           PEOPLE_TABLE\n",
    "       \"\"\"\n",
    "      ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5c53b3df-051f-44f1-8767-155d7ba7663f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.MySqlUdf.uppercase(s: str) -> str>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sql with UDF\n",
    "class MySqlUdf:\n",
    "    def lowercase(s: str) -> str:\n",
    "        return s.lower()\n",
    "    def uppercase(s: str) -> str:\n",
    "        return s.upper()\n",
    "ss.udf.register(\"lowercase_udf\", MySqlUdf.lowercase)\n",
    "ss.udf.register(\"uppercase_udf\", MySqlUdf.uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "763b4ded-5a61-4d09-bf88-0f3ffc7cfb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------+\n",
      "| Name|LOWER_Name|UPPER_Name|\n",
      "+-----+----------+----------+\n",
      "|Jacky|     jacky|     JACKY|\n",
      "| John|      john|      JOHN|\n",
      "|  Tom|       tom|       TOM|\n",
      "| Mark|      mark|      MARK|\n",
      "|Sandy|     sandy|     SANDY|\n",
      "+-----+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ss.sql(\"\"\"\n",
    "        SELECT\n",
    "           Name, \n",
    "           lowercase_udf(Name) AS LOWER_Name,\n",
    "           uppercase_udf(Name) AS UPPER_Name\n",
    "        FROM\n",
    "           PEOPLE_TABLE\n",
    "       \"\"\"\n",
    "      ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d84bf1-696c-4bb6-8330-10e026bd91a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
